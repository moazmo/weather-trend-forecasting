{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸš€ V4 Advanced Multivariate Transformer\n",
    "\n",
    "**Problem**: Standard Transformer treats all 25 features equally, but weather variables have different predictive power.\n",
    "\n",
    "**Solution**: Add **Variable Selection Network (VSN)** + **Gated Residual Networks (GRN)** inspired by Temporal Fusion Transformer.\n",
    "\n",
    "**New Architecture:**\n",
    "1. **Variable Selection**: Learn which weather features matter most\n",
    "2. **Gated Residual Network**: Allow model to skip irrelevant features\n",
    "3. **Deeper Transformer**: More layers for complex interactions\n",
    "4. **Feature-wise Encoding**: Encode weather variables separately before fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"âœ… Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data & Define Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Features: 25 (Static:6, Time:12, Weather:7)\n",
      "ğŸ“Š Sequence: 30 â†’ 7\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../../data/processed/weather_cleaned.csv', parse_dates=['date'])\n",
    "location_stats = pd.read_csv('../models/location_stats.csv')\n",
    "\n",
    "df = df.merge(\n",
    "    location_stats[['country', 'hemisphere_encoded', 'climate_zone_encoded', 'abs_latitude', 'latitude_normalized']],\n",
    "    on='country', how='left'\n",
    ").dropna()\n",
    "\n",
    "# Feature groups for Variable Selection\n",
    "STATIC_COLS = ['latitude', 'longitude', 'abs_latitude', 'latitude_normalized', 'hemisphere_encoded', 'climate_zone_encoded']\n",
    "TIME_COLS = ['month', 'day_of_month', 'day_of_week', 'day_of_year', 'quarter', 'is_weekend',\n",
    "             'month_sin', 'month_cos', 'day_sin', 'day_cos', 'day_of_year_sin', 'day_of_year_cos']\n",
    "WEATHER_COLS = ['temperature_celsius', 'humidity', 'pressure_mb', 'wind_kph', 'precip_mm', 'cloud', 'uv_index']\n",
    "\n",
    "FEATURE_COLS = STATIC_COLS + TIME_COLS + WEATHER_COLS\n",
    "N_STATIC, N_TIME, N_WEATHER = len(STATIC_COLS), len(TIME_COLS), len(WEATHER_COLS)\n",
    "\n",
    "SEQ_LEN = 30\n",
    "PRED_LEN = 7\n",
    "\n",
    "print(f\"ğŸ“Š Features: {len(FEATURE_COLS)} (Static:{N_STATIC}, Time:{N_TIME}, Weather:{N_WEATHER})\")\n",
    "print(f\"ğŸ“Š Sequence: {SEQ_LEN} â†’ {PRED_LEN}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating sequences: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 186/186 [00:01<00:00, 183.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Sequences: (95956, 30, 25), Targets: (95956, 7)\n"
     ]
    }
   ],
   "source": [
    "def create_sequences(df, seq_len=30, pred_len=7):\n",
    "    sequences, targets = [], []\n",
    "    for country in tqdm(df['country'].unique(), desc=\"Creating sequences\"):\n",
    "        country_df = df[df['country'] == country].sort_values('date')\n",
    "        if len(country_df) < seq_len + pred_len:\n",
    "            continue\n",
    "        \n",
    "        data = country_df[FEATURE_COLS].values\n",
    "        temps = country_df['temperature_celsius'].values\n",
    "        \n",
    "        for i in range(len(data) - seq_len - pred_len + 1):\n",
    "            sequences.append(data[i:i+seq_len])\n",
    "            targets.append(temps[i+seq_len:i+seq_len+pred_len])\n",
    "            \n",
    "    return np.array(sequences), np.array(targets)\n",
    "\n",
    "X, y = create_sequences(df, SEQ_LEN, PRED_LEN)\n",
    "print(f\"ğŸ“Š Sequences: {X.shape}, Targets: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train/Test Split & Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Train: 76,764, Test: 19,192\n"
     ]
    }
   ],
   "source": [
    "split_idx = int(len(X) * 0.8)\n",
    "X_train, X_test = X[:split_idx], X[split_idx:]\n",
    "y_train, y_test = y[:split_idx], y[split_idx:]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train.reshape(-1, X_train.shape[-1]))\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train.reshape(-1, X_train.shape[-1])).reshape(X_train.shape)\n",
    "X_test_scaled = scaler.transform(X_test.reshape(-1, X_test.shape[-1])).reshape(X_test.shape)\n",
    "\n",
    "class WeatherDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.FloatTensor(X)\n",
    "        self.y = torch.FloatTensor(y)\n",
    "    def __len__(self): return len(self.X)\n",
    "    def __getitem__(self, idx): return self.X[idx], self.y[idx]\n",
    "\n",
    "BATCH_SIZE = 256\n",
    "train_loader = DataLoader(WeatherDataset(X_train_scaled, y_train), batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(WeatherDataset(X_test_scaled, y_test), batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(f\"ğŸ“Š Train: {X_train.shape[0]:,}, Test: {X_test.shape[0]:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Advanced Architecture Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GatedResidualNetwork(nn.Module):\n",
    "    \"\"\"GRN: Allows model to learn to skip irrelevant inputs.\"\"\"\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "        self.gate = nn.Linear(hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.layer_norm = nn.LayerNorm(output_dim)\n",
    "        self.skip = nn.Linear(input_dim, output_dim) if input_dim != output_dim else nn.Identity()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        hidden = F.elu(self.fc1(x))\n",
    "        hidden = self.dropout(hidden)\n",
    "        output = self.fc2(hidden)\n",
    "        gate = torch.sigmoid(self.gate(hidden))\n",
    "        return self.layer_norm(gate * output + self.skip(x))\n",
    "\n",
    "\n",
    "class VariableSelectionNetwork(nn.Module):\n",
    "    \"\"\"VSN: Learns to weight importance of each input variable.\"\"\"\n",
    "    def __init__(self, input_dim, n_vars, hidden_dim, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.n_vars = n_vars\n",
    "        self.var_grns = nn.ModuleList([GatedResidualNetwork(input_dim // n_vars, hidden_dim, hidden_dim, dropout) \n",
    "                                        for _ in range(n_vars)])\n",
    "        self.softmax_fc = nn.Linear(hidden_dim * n_vars, n_vars)\n",
    "        self.final_grn = GatedResidualNetwork(hidden_dim * n_vars, hidden_dim, hidden_dim, dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x: (batch, seq, features)\n",
    "        batch, seq, _ = x.shape\n",
    "        var_size = x.shape[-1] // self.n_vars\n",
    "        \n",
    "        # Process each variable group\n",
    "        var_outputs = []\n",
    "        for i, grn in enumerate(self.var_grns):\n",
    "            var_input = x[:, :, i*var_size:(i+1)*var_size]\n",
    "            var_outputs.append(grn(var_input))\n",
    "        \n",
    "        # Concatenate and compute importance weights\n",
    "        combined = torch.cat(var_outputs, dim=-1)\n",
    "        weights = F.softmax(self.softmax_fc(combined), dim=-1)  # (batch, seq, n_vars)\n",
    "        \n",
    "        # Weighted combination\n",
    "        weighted = torch.stack(var_outputs, dim=-1) * weights.unsqueeze(-2)\n",
    "        weighted = weighted.sum(dim=-1)\n",
    "        \n",
    "        return self.final_grn(torch.cat(var_outputs, dim=-1)), weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Model parameters: 1,324,167\n"
     ]
    }
   ],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=100):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe.unsqueeze(0))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1), :]\n",
    "\n",
    "\n",
    "class AdvancedWeatherTransformer(nn.Module):\n",
    "    \"\"\"Enhanced Transformer with Variable Selection for weather forecasting.\"\"\"\n",
    "    def __init__(self, input_dim, d_model=128, nhead=8, num_layers=6, dropout=0.2, seq_len=30, pred_len=7):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        # Feature processing with GRN\n",
    "        self.input_grn = GatedResidualNetwork(input_dim, d_model * 2, d_model, dropout)\n",
    "        \n",
    "        # Positional encoding\n",
    "        self.pos_encoder = PositionalEncoding(d_model, seq_len)\n",
    "        \n",
    "        # Main transformer\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model, nhead=nhead, dim_feedforward=d_model*4,\n",
    "            dropout=dropout, batch_first=True, activation='gelu'\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers)\n",
    "        \n",
    "        # Output with GRN\n",
    "        self.output_grn = GatedResidualNetwork(d_model, d_model, d_model, dropout)\n",
    "        self.output_head = nn.Sequential(\n",
    "            nn.Linear(d_model, d_model // 2),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(d_model // 2, pred_len)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Input processing\n",
    "        x = self.input_grn(x)\n",
    "        x = self.pos_encoder(x)\n",
    "        \n",
    "        # Transformer\n",
    "        x = self.transformer(x)\n",
    "        \n",
    "        # Output\n",
    "        x = self.output_grn(x[:, -1, :])\n",
    "        return self.output_head(x)\n",
    "\n",
    "\n",
    "model = AdvancedWeatherTransformer(\n",
    "    input_dim=len(FEATURE_COLS),\n",
    "    d_model=128,\n",
    "    nhead=8,\n",
    "    num_layers=6,\n",
    "    dropout=0.15\n",
    ").to(device)\n",
    "\n",
    "print(f\"ğŸ“Š Model parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training with Cosine Annealing & Gradient Clipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Starting training...\n",
      "Epoch  10 | Train: 1.8165 | Val: 1.5746 | LR: 0.001000\n",
      "Epoch  20 | Train: 1.6239 | Val: 1.5883 | LR: 0.000500\n",
      "Epoch  30 | Train: 1.4885 | Val: 1.5667 | LR: 0.001000\n",
      "Epoch  40 | Train: 1.4841 | Val: 1.6156 | LR: 0.000854\n",
      "\n",
      "â¹ï¸ Early stopping at epoch 44\n",
      "\n",
      "âœ… Best validation loss: 1.5637\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.HuberLoss(delta=1.0)  # More robust than MSE\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.02)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2)\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "best_state = None\n",
    "patience = 20\n",
    "patience_counter = 0\n",
    "\n",
    "print(\"ğŸš€ Starting training...\")\n",
    "for epoch in range(150):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(X_batch)\n",
    "        loss = criterion(pred, y_batch)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    scheduler.step()\n",
    "    \n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in test_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            val_loss += criterion(model(X_batch), y_batch).item()\n",
    "    \n",
    "    train_loss /= len(train_loader)\n",
    "    val_loss /= len(test_loader)\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1:3d} | Train: {train_loss:.4f} | Val: {val_loss:.4f} | LR: {scheduler.get_last_lr()[0]:.6f}\")\n",
    "    \n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"\\nâ¹ï¸ Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "\n",
    "model.load_state_dict(best_state)\n",
    "print(f\"\\nâœ… Best validation loss: {best_val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Test Results:\n",
      "   MAE:  2.00Â°C\n",
      "   RMSE: 2.76Â°C\n",
      "\n",
      "ğŸ“Š MAE per forecast day:\n",
      "   Day 1: 1.97Â°C\n",
      "   Day 2: 1.95Â°C\n",
      "   Day 3: 1.94Â°C\n",
      "   Day 4: 1.94Â°C\n",
      "   Day 5: 1.99Â°C\n",
      "   Day 6: 2.05Â°C\n",
      "   Day 7: 2.14Â°C\n",
      "\n",
      "ğŸ“Š Comparison:\n",
      "   V2.3 Transformer:    2.05Â°C\n",
      "   V3.0 Multivariate:   2.07Â°C\n",
      "   V4.0 Advanced:       2.00Â°C âœ… IMPROVED!\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "all_preds, all_targets = [], []\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        preds = model(X_batch).cpu().numpy()\n",
    "        all_preds.extend(preds)\n",
    "        all_targets.extend(y_batch.numpy())\n",
    "\n",
    "all_preds = np.array(all_preds)\n",
    "all_targets = np.array(all_targets)\n",
    "\n",
    "mae = np.mean(np.abs(all_preds - all_targets))\n",
    "rmse = np.sqrt(np.mean((all_preds - all_targets) ** 2))\n",
    "\n",
    "print(f\"ğŸ“Š Test Results:\")\n",
    "print(f\"   MAE:  {mae:.2f}Â°C\")\n",
    "print(f\"   RMSE: {rmse:.2f}Â°C\")\n",
    "\n",
    "print(f\"\\nğŸ“Š MAE per forecast day:\")\n",
    "for i in range(PRED_LEN):\n",
    "    day_mae = np.mean(np.abs(all_preds[:, i] - all_targets[:, i]))\n",
    "    print(f\"   Day {i+1}: {day_mae:.2f}Â°C\")\n",
    "\n",
    "# Compare with previous models\n",
    "print(f\"\\nğŸ“Š Comparison:\")\n",
    "print(f\"   V2.3 Transformer:    2.05Â°C\")\n",
    "print(f\"   V3.0 Multivariate:   2.07Â°C\")\n",
    "print(f\"   V4.0 Advanced:       {mae:.2f}Â°C {'âœ… IMPROVED!' if mae < 2.05 else 'âš ï¸ Similar'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved advanced model to ../models/advanced_transformer.pt\n",
      "   MAE: 2.00Â°C\n"
     ]
    }
   ],
   "source": [
    "save_path = '../models/advanced_transformer.pt'\n",
    "checkpoint = {\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'input_dim': len(FEATURE_COLS),\n",
    "    'd_model': 128,\n",
    "    'nhead': 8,\n",
    "    'num_layers': 6,\n",
    "    'dropout': 0.15,\n",
    "    'seq_len': SEQ_LEN,\n",
    "    'pred_len': PRED_LEN,\n",
    "    'feature_cols': FEATURE_COLS,\n",
    "    'mae': mae,\n",
    "    'architecture': 'AdvancedWeatherTransformer'\n",
    "}\n",
    "torch.save(checkpoint, save_path)\n",
    "joblib.dump(scaler, '../models/advanced_scaler.joblib')\n",
    "print(f\"âœ… Saved advanced model to {save_path}\")\n",
    "print(f\"   MAE: {mae:.2f}Â°C\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
