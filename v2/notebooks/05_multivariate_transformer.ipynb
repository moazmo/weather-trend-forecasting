{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üß™ V3 Multivariate Transformer Training\n",
    "\n",
    "Train a **Multivariate Transformer model** that uses Temperature, Humidity, Pressure, Wind, and Cloud Cover.\n",
    "\n",
    "**Goal:**\n",
    "- Break the 2.05¬∞C MAE plateau by learning physical interactions between weather variables.\n",
    "\n",
    "**New Features:**\n",
    "- `humidity`\n",
    "- `pressure_mb`\n",
    "- `wind_kph`\n",
    "- `cloud`\n",
    "- `precip_mm`\n",
    "- `uv_index`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "import json\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"‚úÖ Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data & Define Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Features: 25, Seq: 30 ‚Üí Pred: 7\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../../data/processed/weather_cleaned.csv', parse_dates=['date'])\n",
    "location_stats = pd.read_csv('../models/location_stats.csv')\n",
    "\n",
    "df = df.merge(\n",
    "    location_stats[['country', 'hemisphere_encoded', 'climate_zone_encoded', 'abs_latitude', 'latitude_normalized']],\n",
    "    on='country', how='left'\n",
    ").dropna()\n",
    "\n",
    "# Define Combined Feature Set (Static + Dynamic + Multivariate)\n",
    "FEATURE_COLS = [\n",
    "    # Static / Semi-static\n",
    "    'latitude', 'longitude', 'abs_latitude', 'latitude_normalized',\n",
    "    'hemisphere_encoded', 'climate_zone_encoded',\n",
    "    # Time\n",
    "    'month', 'day_of_month', 'day_of_week', 'day_of_year', 'quarter', 'is_weekend',\n",
    "    'month_sin', 'month_cos', 'day_sin', 'day_cos', 'day_of_year_sin', 'day_of_year_cos',\n",
    "    # Dynamic Weather Drivers (The New Stuff)\n",
    "    'temperature_celsius', 'humidity', 'pressure_mb', 'wind_kph', 'precip_mm', 'cloud', 'uv_index'\n",
    "]\n",
    "\n",
    "SEQ_LEN = 30\n",
    "PRED_LEN = 7\n",
    "\n",
    "print(f\"üìä Features: {len(FEATURE_COLS)}, Seq: {SEQ_LEN} ‚Üí Pred: {PRED_LEN}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create Sequences (Multivariate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating sequences: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 186/186 [00:00<00:00, 244.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Sequences: (95956, 30, 25), Targets: (95956, 7)\n"
     ]
    }
   ],
   "source": [
    "def create_sequences(df, seq_len=30, pred_len=7):\n",
    "    sequences, targets = [], []\n",
    "    for country in tqdm(df['country'].unique(), desc=\"Creating sequences\"):\n",
    "        country_df = df[df['country'] == country].sort_values('date')\n",
    "        if len(country_df) < seq_len + pred_len:\n",
    "            continue\n",
    "        \n",
    "        # Select ALL feature columns\n",
    "        data = country_df[FEATURE_COLS].values\n",
    "        temps = country_df['temperature_celsius'].values\n",
    "        \n",
    "        for i in range(len(data) - seq_len - pred_len + 1):\n",
    "            sequences.append(data[i:i+seq_len])\n",
    "            targets.append(temps[i+seq_len:i+seq_len+pred_len])\n",
    "            \n",
    "    return np.array(sequences), np.array(targets)\n",
    "\n",
    "X, y = create_sequences(df, SEQ_LEN, PRED_LEN)\n",
    "print(f\"üìä Sequences: {X.shape}, Targets: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train/Test Split & Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Train: 76,764, Test: 19,192\n"
     ]
    }
   ],
   "source": [
    "split_idx = int(len(X) * 0.8)\n",
    "X_train, X_test = X[:split_idx], X[split_idx:]\n",
    "y_train, y_test = y[:split_idx], y[split_idx:]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "# Reshape to 2D for scaling: (Samples * SeqLen, Features)\n",
    "scaler.fit(X_train.reshape(-1, X_train.shape[-1]))\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train.reshape(-1, X_train.shape[-1])).reshape(X_train.shape)\n",
    "X_test_scaled = scaler.transform(X_test.reshape(-1, X_test.shape[-1])).reshape(X_test.shape)\n",
    "\n",
    "print(f\"üìä Train: {X_train.shape[0]:,}, Test: {X_test.shape[0]:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeatherDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.FloatTensor(X)\n",
    "        self.y = torch.FloatTensor(y)\n",
    "    def __len__(self): return len(self.X)\n",
    "    def __getitem__(self, idx): return self.X[idx], self.y[idx]\n",
    "\n",
    "BATCH_SIZE = 256\n",
    "train_loader = DataLoader(WeatherDataset(X_train_scaled, y_train), batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(WeatherDataset(X_test_scaled, y_test), batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Definition (Previous V2.3 Architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Model parameters: 204,039\n"
     ]
    }
   ],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=100):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe.unsqueeze(0))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1), :]\n",
    "\n",
    "class WeatherTransformer(nn.Module):\n",
    "    def __init__(self, input_dim, d_model=64, nhead=8, num_layers=4, dropout=0.2, seq_len=30, pred_len=7):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.input_projection = nn.Linear(input_dim, d_model)\n",
    "        self.pos_encoder = PositionalEncoding(d_model, seq_len)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, dim_feedforward=d_model*4, dropout=dropout, batch_first=True, activation='gelu')\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers)\n",
    "        self.output_head = nn.Sequential(\n",
    "            nn.LayerNorm(d_model),\n",
    "            nn.Linear(d_model, d_model // 2),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(d_model // 2, pred_len)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.input_projection(x) * math.sqrt(self.d_model)\n",
    "        x = self.pos_encoder(x)\n",
    "        x = self.transformer(x)\n",
    "        return self.output_head(x[:, -1, :])\n",
    "\n",
    "model = WeatherTransformer(\n",
    "    input_dim=len(FEATURE_COLS),\n",
    "    d_model=64,\n",
    "    nhead=8,\n",
    "    num_layers=4,\n",
    "    dropout=0.2\n",
    ").to(device)\n",
    "print(f\"üìä Model parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting training...\n",
      "Epoch   5 | Train: 15.4704 | Val: 8.5593\n",
      "Epoch  10 | Train: 14.3770 | Val: 8.4413\n",
      "Epoch  15 | Train: 13.1428 | Val: 8.3926\n",
      "Epoch  20 | Train: 12.0722 | Val: 7.9842\n",
      "Epoch  25 | Train: 11.2357 | Val: 8.0473\n",
      "Epoch  30 | Train: 10.6299 | Val: 8.0825\n",
      "Epoch  35 | Train: 9.9828 | Val: 8.0768\n",
      "\n",
      "‚èπÔ∏è Early stopping at epoch 38\n",
      "\n",
      "‚úÖ Best validation loss: 7.9469\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0005, weight_decay=0.01)\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "best_state = None\n",
    "patience = 15\n",
    "patience_counter = 0\n",
    "\n",
    "print(\"üöÄ Starting training...\")\n",
    "for epoch in range(100):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(X_batch)\n",
    "        loss = criterion(pred, y_batch)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in test_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            val_loss += criterion(model(X_batch), y_batch).item()\n",
    "    \n",
    "    train_loss /= len(train_loader)\n",
    "    val_loss /= len(test_loader)\n",
    "    \n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print(f\"Epoch {epoch+1:3d} | Train: {train_loss:.4f} | Val: {val_loss:.4f}\")\n",
    "    \n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_state = model.state_dict().copy()\n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"\\n‚èπÔ∏è Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "\n",
    "model.load_state_dict(best_state)\n",
    "print(f\"\\n‚úÖ Best validation loss: {best_val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Test Results:\n",
      "   MAE:  2.07¬∞C\n",
      "   RMSE: 2.84¬∞C\n",
      "\n",
      "üìä MAE per forecast day:\n",
      "   Day 1: 2.03¬∞C\n",
      "   Day 2: 2.03¬∞C\n",
      "   Day 3: 2.04¬∞C\n",
      "   Day 4: 2.05¬∞C\n",
      "   Day 5: 2.07¬∞C\n",
      "   Day 6: 2.12¬∞C\n",
      "   Day 7: 2.17¬∞C\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "all_preds, all_targets = [], []\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        preds = model(X_batch).cpu().numpy()\n",
    "        all_preds.extend(preds)\n",
    "        all_targets.extend(y_batch.numpy())\n",
    "\n",
    "all_preds = np.array(all_preds)\n",
    "all_targets = np.array(all_targets)\n",
    "\n",
    "mae = np.mean(np.abs(all_preds - all_targets))\n",
    "rmse = np.sqrt(np.mean((all_preds - all_targets) ** 2))\n",
    "\n",
    "print(f\"üìä Test Results:\")\n",
    "print(f\"   MAE:  {mae:.2f}¬∞C\")\n",
    "print(f\"   RMSE: {rmse:.2f}¬∞C\")\n",
    "\n",
    "# Per-day MAE\n",
    "print(f\"\\nüìä MAE per forecast day:\")\n",
    "for i in range(PRED_LEN):\n",
    "    day_mae = np.mean(np.abs(all_preds[:, i] - all_targets[:, i]))\n",
    "    print(f\"   Day {i+1}: {day_mae:.2f}¬∞C\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save Model Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved multivariate model to ../models/multivariate_transformer.pt\n",
      "   MAE: 2.07¬∞C\n"
     ]
    }
   ],
   "source": [
    "# Save to v2/models/\n",
    "save_path = '../models/multivariate_transformer.pt'\n",
    "checkpoint = {\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'input_dim': len(FEATURE_COLS),\n",
    "    'd_model': 64,\n",
    "    'nhead': 8,\n",
    "    'num_layers': 4,\n",
    "    'dropout': 0.2,\n",
    "    'seq_len': SEQ_LEN,\n",
    "    'pred_len': PRED_LEN,\n",
    "    'feature_cols': FEATURE_COLS,\n",
    "    'mae': mae\n",
    "}\n",
    "torch.save(checkpoint, save_path)\n",
    "joblib.dump(scaler, '../models/multivariate_scaler.joblib')\n",
    "print(f\"‚úÖ Saved multivariate model to {save_path}\")\n",
    "print(f\"   MAE: {mae:.2f}¬∞C\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
